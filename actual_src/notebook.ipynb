{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.000e+00 1.480e+02 7.200e+01 3.500e+01 0.000e+00 3.360e+01 6.270e-01\n",
      "  5.000e+01]\n",
      " [1.000e+00 8.500e+01 6.600e+01 2.900e+01 0.000e+00 2.660e+01 3.510e-01\n",
      "  3.100e+01]\n",
      " [8.000e+00 1.830e+02 6.400e+01 0.000e+00 0.000e+00 2.330e+01 6.720e-01\n",
      "  3.200e+01]\n",
      " [1.000e+00 8.900e+01 6.600e+01 2.300e+01 9.400e+01 2.810e+01 1.670e-01\n",
      "  2.100e+01]\n",
      " [0.000e+00 1.370e+02 4.000e+01 3.500e+01 1.680e+02 4.310e+01 2.288e+00\n",
      "  3.300e+01]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('/Users/renegonzalez/Desktop/DNN LoL/train_set.csv', delimiter=',', dtype=np.float32)\n",
    "# Split the data into train and test sets 4:1\n",
    "\n",
    "X_train, y_train, X_test, y_test = \n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model architecture lol\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dropout(0.69, input_dim=8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(160, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dropout(0.69))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.69))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dropout(0.69))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dropout(0.69))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='elu', kernel_initializer='he_normal'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1214d0e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00\n"
     ]
    }
   ],
   "source": [
    "# Printe and display the  accuracy\n",
    "_, accuracy = model.evaluate(X, y, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "691eb79eb72537d0883bca6d88dcdf7f09ae44591fb81d1bfe079677ef04f4ec"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('3.10.1': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
